<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Niel Ok</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="site.css">
</head>
<body>
  <div class="content">
    <div class="top-bar">
      <div class="top-left">
        <a href="/" class="active">home</a>
        <a href="experience/">experience</a>
        <a href="/writing/">writing</a>
        <a href="/reading/">reading</a>
      </div>
    </div>

    <h1>Niel Jongwhan Ok</h1>
    <div class="description">
      Systems+theory guy building Null Labs as cofounder/CTO leaving Stanford.
    </div>

    <h2>About Me</h2>
    <ul class="about-list">
      <li>born in Louisiana, raised there and in Colorado, Texas, Ohio</li>
      <li>have been working in AI since I got my first laptop in 2019. spent early days building diagnostic and generative models for medical imaging</li>
      <li>became interested in quantum computing at 15 after learning about entanglement and ER=EPR. wrote a simulator supporting intermediate statevector extraction with sponsorship from Google Quantum, useful for verifying quantum circuits in ways not supported by existing simulators from IBM and Google</li>
      <li>started Stanford as an EE undergrad</li>
      <li>curiosity about the gap between neural nets and the brain led me to research in theoretical neuroscience and neuromorphic computing at Stanford Brains in Silicon, where I got to get down to the level of differential equations modeling dendrite-level dynamics</li>
      <li>spent time between DeepMind and a DeepMind spinout (hire number 2) working on automating AI research and new inference scaling and interpretability methods for robotics/text diffusion models</li>
      <li>co-founder/CTO of Null Labs</li>
      <li>believe that computable physics and variation could be much better utilized in training autonomous systems than what is currently being done</li>
    </ul>

    <h2>Thoughts</h2>
    <ul class="about-list">
      <li>language can structure thought in useful ways but also restricts it</li>
      <li>scaling laws have shown us that learning is incremental given a fixed framework. different frameworks probably lead to different slopes.</li>
      <li>with the right framework, learning might not even be incremental</li>
      <li>AI progress has plateaued on internet data. the next frontier will involve harnessing computable physics, structured variation, and interactions with environments more effectively</li>
      <li>a lot of physics consists of abstractions that reduce the interactions of countless particles into tractable computations. some abstractions, however, aren't so computable</li>
      <li>neural networks themselves could serve as functional approximators for complex interactions not considered easily computable in traditional physics</li>
      <li>physics, math, language, and computation all have generative asymmetry. they all exhibit how small sets of rules can lead to rich behaviors. there may be a reason for this structure</li>
      <li>based on the performance of recent AI models, it seems consciousness may not be required to create digital beings that can perform tasks at the level of human intelligence. what exactly is the purpose of consciousness, then?</li>
    </ul>

    <div class="footer">
      <div class="footer-left">
        <div class="social-links">
          <a href="https://github.com/NielOk" target="_blank">github</a>
          <a href="https://twitter.com/nielok20" target="_blank">twitter</a>
          <a href="https://www.linkedin.com/in/niel-ok" target="_blank">linkedin</a>
          <a href="https://huggingface.co/NielOk" target="_blank">hugging face</a>
        </div>
        <div class="emails">
          
          <div>nielok@stanford.edu</div>
          <div>niel.jongwhan.ok@gmail.com</div>
        </div>
      </div>
    </div>
  </div>
</body>
</html>
