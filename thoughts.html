<!DOCTYPE html>
<html lang="en">
<head>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <meta charset="UTF-8">
  <title>Thoughts â€” Niel Ok</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="site.css">
  </style>
</head>
<body>
  <div class="content">
    <div class="top-bar">
      <div class="top-left">
        <a href="index.html">home</a>
        <a href="experience.html">experience</a>
        <a href="mybrain.html">writing</a>
        <a href="reading.html">reading</a>
        <a href="thoughts.html" class="active">thoughts</a>
      </div>
    </div>
    
    <ul style="font-size: 13px; margin-bottom: 2.5rem; padding-left: 1.2rem; list-style: disc;">
      <li>In our most fundamental studies, such as physics, mathematics, language, and computation, we find the same pattern repeated: a nearly boundless landscape of possibilities arising from a surprisingly small set of rules. Why does this generative asymmetry appear so universally? What's its source? Are human brains optimized to find small sets of rules given the vast possibilities they see playing out in the world? Or is it the other way around? Why, in physics, does it seem like we attempt to find a small set of rules given many observations while doing the opposite with language, mathematics, and computation, where we define small sets of rules that can generate a wide variety of expressions?</li>
      <p></p>
      <li>What would happen if you tried to accelerate the study of physics by deploying a bunch of intelligent agents to search for the fundamental rules together? If these agents are not individually sure of the rules they find, how would you increase their confidence? Probably by making them share the information they find with one another, which would then require each agent to critically evaluate the information they receive. Doesn't this sound a lot like humanity? Could humanity just be a big group of intelligent computers collaborating in an almost optimal way to find the rules that govern the universe?</li>
      <p></p>
      <li>Based on the progress of AI, it seems that consciousness may not be required to create digital beings that can perform intelligent tasks at the level of human intelligence. What exactly is the purpose of consciousness, then? Why have we evolved it? Does it start to matter more when making real-time decisions in the physical world?</li>
    </ul>
  </div>

</body>
</html>